[2018-02-17 02:42:46]     INFO --- 2008 (ADSAssign1Part2Final.py:77)
[2018-02-17 02:42:46]     INFO --- Zipped file directory created!! (ADSAssign1Part2Final.py:85)
[2018-02-17 02:42:46]     INFO --- UnZipped file directory created!! (ADSAssign1Part2Final.py:93)
[2018-02-17 02:42:47]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:42:51]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:42:53]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:42:59]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:06]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:08]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:12]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:16]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:18]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:23]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:26]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:32]     INFO --- Retrieving zipped log file (ADSAssign1Part2Final.py:110)
[2018-02-17 02:43:33]     INFO --- log20080601.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:34]     INFO --- log20080501.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:36]     INFO --- log20080401.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:38]     INFO --- log20081201.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:44]     INFO --- log20080201.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:45]     INFO --- log20080301.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:48]     INFO --- log20080701.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:48]     INFO --- log20080901.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:49]     INFO --- log20080101.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:51]     INFO --- log20081101.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:53]     INFO --- log20080801.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:57]     INFO --- log20081001.csv successfully extracted to folder: unzippedfiles. (ADSAssign1Part2Final.py:127)
[2018-02-17 02:43:57]     INFO --- Graphical_images directory created!! (ADSAssign1Part2Final.py:142)
[2018-02-17 02:44:01]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:44:02]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:44:02]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:44:02]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:44:02]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:44:02]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:44:03]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:44:03]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:44:03]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:44:05]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:44:08]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:44:11]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:44:11]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:44:12]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:44:12]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:44:12]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:44:13]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:44:13]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:44:13]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:44:14]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:44:14]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:44:14]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:44:14]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:44:14]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:44:14]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:44:14]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:44:14]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:44:14]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:44:15]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:44:15]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:44:15]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:44:16]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:44:17]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:44:20]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:44:21]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:44:21]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:44:21]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:44:21]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:44:21]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:44:22]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:44:22]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:44:22]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:44:26]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:44:30]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:44:35]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:44:35]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:44:36]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:44:36]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:44:37]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:44:37]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:44:38]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:44:38]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:44:39]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:44:39]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:44:39]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:44:39]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:44:39]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:44:40]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:44:40]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:44:40]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:44:40]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:44:40]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:44:40]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:44:41]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:44:42]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:44:42]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:44:44]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:44:44]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:44:44]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:44:44]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:44:44]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:44:44]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:44:45]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:44:45]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:44:45]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:44:47]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:44:49]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:44:50]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:44:50]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:44:51]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:44:51]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:44:51]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:44:51]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:44:52]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:44:52]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:44:52]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:44:52]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:44:52]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:44:52]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:44:53]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:44:53]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:44:53]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:44:53]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:44:53]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:44:53]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:44:53]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:44:53]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:44:54]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:44:54]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:45:04]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:45:05]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:45:05]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:45:05]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:45:05]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:45:05]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:45:06]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:45:06]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:45:06]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:45:12]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:45:17]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:45:22]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:45:22]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:45:23]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:45:23]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:45:24]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:45:24]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:45:25]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:45:25]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:45:26]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:45:26]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:45:27]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:45:27]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:45:27]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:45:27]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:45:27]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:45:27]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:45:27]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:45:28]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:45:28]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:45:29]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:45:30]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:45:30]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:45:31]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:45:31]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:45:31]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:45:31]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:45:31]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:45:31]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:45:31]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:45:31]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:45:31]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:45:32]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:45:33]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:45:34]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:45:34]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:45:34]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:45:34]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:45:34]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:45:34]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:45:34]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:45:34]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:45:35]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:45:35]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:45:35]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:45:35]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:45:35]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:45:35]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:45:35]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:45:35]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:45:35]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:45:35]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:45:35]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:45:35]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:45:36]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:45:36]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:45:38]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:45:39]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:45:39]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:45:39]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:45:39]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:45:39]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:45:39]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:45:39]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:45:39]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:45:42]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:45:44]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:45:46]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:45:46]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:45:47]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:45:47]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:45:47]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:45:47]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:45:48]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:45:48]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:45:48]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:45:48]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:45:48]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:45:49]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:45:49]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:45:49]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:45:49]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:45:49]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:45:49]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:45:49]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:45:49]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:45:50]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:45:52]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:45:53]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:45:56]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:45:56]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:45:56]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:45:56]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:45:56]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:45:56]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:45:57]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:45:57]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:45:57]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:45:59]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:46:02]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:46:05]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:46:05]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:46:05]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:46:05]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:46:06]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:46:06]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:46:06]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:46:06]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:46:07]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:46:07]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:46:07]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:46:07]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:46:07]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:46:08]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:46:08]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:46:08]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:46:08]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:46:08]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:46:08]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:46:08]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:46:09]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:46:10]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:46:12]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:46:13]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:46:13]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:46:13]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:46:13]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:46:13]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:46:14]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:46:14]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:46:14]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:46:16]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:46:19]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:46:22]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:46:22]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:46:22]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:46:22]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:46:23]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:46:23]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:46:23]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:46:23]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:46:24]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:46:24]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:46:24]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:46:24]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:46:24]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:46:24]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:46:24]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:46:24]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:46:24]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:46:25]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:46:25]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:46:25]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:46:26]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:46:26]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:46:30]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:46:30]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:46:30]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:46:30]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:46:31]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:46:31]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:46:31]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:46:31]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:46:31]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:46:35]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:46:39]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:46:43]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:46:43]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:46:44]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:46:44]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:46:45]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:46:45]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:46:46]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:46:46]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:46:46]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:46:47]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:46:47]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:46:47]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:46:47]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:46:47]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:46:47]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:46:47]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:46:47]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:46:48]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:46:48]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:46:48]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:46:50]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:46:50]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:46:52]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:46:52]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:46:52]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:46:52]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:46:52]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:46:52]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:46:52]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:46:52]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:46:52]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:46:54]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:46:56]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:46:57]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:46:57]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:46:58]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:46:58]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:46:58]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:46:58]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:46:59]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:46:59]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:46:59]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:46:59]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:46:59]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:46:59]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:46:59]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:46:59]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:46:59]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:46:59]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:46:59]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:47:00]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:47:00]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:47:00]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:47:01]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:47:01]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:47:12]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:47:13]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:47:13]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:47:13]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:47:13]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:47:13]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:47:14]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:47:14]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:47:14]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:47:18]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:47:22]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:47:26]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:47:26]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:47:26]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:47:26]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:47:27]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:47:28]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:47:28]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:47:28]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:47:29]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:47:29]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:47:29]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:47:30]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:47:30]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:47:30]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:47:30]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:47:30]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:47:30]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:47:31]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:47:31]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:47:31]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:47:35]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:47:35]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:47:37]     INFO --- Calculated the missing values in each coloumn (ADSAssign1Part2Final.py:151)
[2018-02-17 02:47:37]     INFO --- Finding the NaN values in each coloumn (ADSAssign1Part2Final.py:153)
[2018-02-17 02:47:37]     INFO --- Working on the Browser Coloumn (ADSAssign1Part2Final.py:154)
[2018-02-17 02:47:37]     INFO --- Grouping the values of all the browsers and storing in a dataframe (ADSAssign1Part2Final.py:157)
[2018-02-17 02:47:37]     INFO --- Counting the frequency of each browser type used in descending order (ADSAssign1Part2Final.py:160)
[2018-02-17 02:47:37]     INFO --- Selecting the brower at the index 0(as it will be the maximum used browser) (ADSAssign1Part2Final.py:163)
[2018-02-17 02:47:37]     INFO --- confirming that no NaN values are present on the browser coloumn (ADSAssign1Part2Final.py:166)
[2018-02-17 02:47:37]     INFO --- Working on the Size Coloumn (ADSAssign1Part2Final.py:167)
[2018-02-17 02:47:37]     INFO --- Replacing the file size for ext : txt, by the mean of all the file size corresponding to txt (ADSAssign1Part2Final.py:168)
[2018-02-17 02:47:39]     INFO --- Replacing the file size with NaN values for ext : htm, by the mean of all the file size corresponding to htm (ADSAssign1Part2Final.py:174)
[2018-02-17 02:47:40]     INFO --- Replacing the file size with NaN values for ext : xml, by the mean of all the file size corresponding to xml (ADSAssign1Part2Final.py:180)
[2018-02-17 02:47:42]     INFO --- To check how many NaN values are remaining  (ADSAssign1Part2Final.py:186)
[2018-02-17 02:47:42]     INFO --- Replacing the file size for rest of the files with the mean of file size of txt extension, as it is the max used (ADSAssign1Part2Final.py:187)
[2018-02-17 02:47:42]     INFO --- Working on all other coloumns (ADSAssign1Part2Final.py:190)
[2018-02-17 02:47:42]     INFO --- If cik,Accession,ip,date are empty fields drop the records (ADSAssign1Part2Final.py:191)
[2018-02-17 02:47:43]     INFO --- Calculating the max categorical value in other coloumns( code, zone,extention,idx,find) and filling the NaNs (ADSAssign1Part2Final.py:197)
[2018-02-17 02:47:43]     INFO --- Filling empty values with Categorical Values for coloumns (norefer,noagent,nocrawler) (ADSAssign1Part2Final.py:204)
[2018-02-17 02:47:43]     INFO --- Missing data is handled successfully (ADSAssign1Part2Final.py:209)
[2018-02-17 02:47:43]     INFO --- Calculating Summary metrics of clean data (ADSAssign1Part2Final.py:212)
[2018-02-17 02:47:43]     INFO --- Mean and Median sizes for each Browser (ADSAssign1Part2Final.py:238)
[2018-02-17 02:47:43]     INFO --- Top 15 most searched CIKs with the count (ADSAssign1Part2Final.py:247)
[2018-02-17 02:47:43]     INFO --- Compute distinct count of ip per month i.e. per log file (ADSAssign1Part2Final.py:253)
[2018-02-17 02:47:43]     INFO --- Computing the count of status code on the basis of ip (ADSAssign1Part2Final.py:258)
[2018-02-17 02:47:44]     INFO --- Average of file size is computed (ADSAssign1Part2Final.py:265)
[2018-02-17 02:47:44]     INFO --- Number of request per day is computed (ADSAssign1Part2Final.py:269)
[2018-02-17 02:47:44]     INFO --- Mean of file size on the basis of code status (ADSAssign1Part2Final.py:273)
[2018-02-17 02:47:44]     INFO --- Summary metrics computed succesfully!! (ADSAssign1Part2Final.py:276)
[2018-02-17 02:47:44]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:284)
[2018-02-17 02:47:44]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:300)
[2018-02-17 02:47:44]     INFO --- graphical analysis started (ADSAssign1Part2Final.py:307)
[2018-02-17 02:47:44]     INFO --- graphical analysis end (ADSAssign1Part2Final.py:323)
[2018-02-17 02:47:45]     INFO --- Anomalies analysis started (ADSAssign1Part2Final.py:383)
[2018-02-17 02:47:45]     INFO --- Anomalies analysis ended (ADSAssign1Part2Final.py:391)
[2018-02-17 02:47:46]    DEBUG --- Loading variable profile from defaults. (session.py:287)
[2018-02-17 02:47:46]    DEBUG --- Loading variable config_file from defaults. (session.py:287)
[2018-02-17 02:47:46]    DEBUG --- Loading variable credentials_file from defaults. (session.py:287)
[2018-02-17 02:47:46]    DEBUG --- Loading variable data_path from defaults. (session.py:287)
[2018-02-17 02:47:46]    DEBUG --- Loading variable profile from defaults. (session.py:287)
[2018-02-17 02:47:46]    DEBUG --- Loading variable ca_bundle from defaults. (session.py:287)
[2018-02-17 02:47:46]    DEBUG --- Loading variable profile from defaults. (session.py:287)
[2018-02-17 02:47:46]    DEBUG --- Loading variable api_versions from defaults. (session.py:287)
[2018-02-17 02:47:46]    DEBUG --- Loading JSON file: /usr/local/lib/python3.6/site-packages/botocore/data/endpoints.json (loaders.py:174)
[2018-02-17 02:47:47]    DEBUG --- Loading variable profile from defaults. (session.py:287)
[2018-02-17 02:47:47]    DEBUG --- Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f91b5372378> (hooks.py:209)
[2018-02-17 02:47:47]    DEBUG --- Loading JSON file: /usr/local/lib/python3.6/site-packages/botocore/data/s3/2006-03-01/service-2.json (loaders.py:174)
[2018-02-17 02:47:47]    DEBUG --- Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f91b53d09d8> (hooks.py:209)
[2018-02-17 02:47:47]    DEBUG --- Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f91adea1620> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f91b53d07b8> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- The s3 config key is not a dictionary type, ignoring its value of: None (args.py:160)
[2018-02-17 02:47:48]    DEBUG --- Setting s3 timeout as (60, 60) (endpoint.py:131)
[2018-02-17 02:47:48]    DEBUG --- Loading JSON file: /usr/local/lib/python3.6/site-packages/botocore/data/_retry.json (loaders.py:174)
[2018-02-17 02:47:48]    DEBUG --- Registering retry handlers for service: s3 (client.py:122)
[2018-02-17 02:47:48]    DEBUG --- Defaulting to S3 virtual host style addressing with path style addressing fallback. (client.py:189)
[2018-02-17 02:47:48]    DEBUG --- Event before-parameter-build.s3.CreateBucket: calling handler <function validate_bucket_name at 0x7f91b5389c80> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Event before-parameter-build.s3.CreateBucket: calling handler <bound method S3RegionRedirector.redirect_from_cache of <botocore.utils.S3RegionRedirector object at 0x7f91a811c9b0>> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Event before-parameter-build.s3.CreateBucket: calling handler <function generate_idempotent_uuid at 0x7f91b53898c8> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Event before-call.s3.CreateBucket: calling handler <function add_expect_header at 0x7f91b538c1e0> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Event before-call.s3.CreateBucket: calling handler <bound method S3RegionRedirector.set_request_url of <botocore.utils.S3RegionRedirector object at 0x7f91a811c9b0>> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Making request for OperationModel(name=CreateBucket) (verify_ssl=True) with params: {'url_path': '/ads-part2-assign2', 'query_string': {}, 'method': 'PUT', 'headers': {'User-Agent': 'Boto3/1.5.30 Python/3.6.4 Linux/4.4.111-boot2docker Botocore/1.8.44'}, 'body': b'', 'url': 'https://s3.amazonaws.com/ads-part2-assign2', 'context': {'client_region': 'us-east-1', 'client_config': <botocore.config.Config object at 0x7f91a5eccb00>, 'has_streaming_input': False, 'auth_type': None, 'signing': {'bucket': 'ads-part2-assign2'}}} (endpoint.py:142)
[2018-02-17 02:47:48]    DEBUG --- Event request-created.s3.CreateBucket: calling handler <bound method RequestSigner.handler of <botocore.signers.RequestSigner object at 0x7f91a5ec60f0>> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Event choose-signer.s3.CreateBucket: calling handler <bound method ClientCreator._default_s3_presign_to_sigv2 of <botocore.client.ClientCreator object at 0x7f91a5eb5fd0>> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Event choose-signer.s3.CreateBucket: calling handler <function set_operation_specific_signer at 0x7f91b53897b8> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Event before-sign.s3.CreateBucket: calling handler <function fix_s3_host at 0x7f91b56d2268> (hooks.py:209)
[2018-02-17 02:47:48]    DEBUG --- Calculating signature using v4 auth. (auth.py:359)
[2018-02-17 02:47:48]    DEBUG --- CanonicalRequest:
PUT
/ads-part2-assign2

host:s3.amazonaws.com
x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
x-amz-date:20180217T024748Z

host;x-amz-content-sha256;x-amz-date
e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 (auth.py:360)
[2018-02-17 02:47:48]    DEBUG --- StringToSign:
AWS4-HMAC-SHA256
20180217T024748Z
20180217/us-east-1/s3/aws4_request
b602653cd11c5e9aa54d98c2618ce3b7f9c54b318732ae71123775d8e734db9e (auth.py:362)
[2018-02-17 02:47:48]    DEBUG --- Signature:
00c80e4a218d3e8ca27e0750422333f3093b94d5467c7d237c5e7ae85cbce8a9 (auth.py:364)
[2018-02-17 02:47:48]    DEBUG --- Sending http request: <PreparedRequest [PUT]> (endpoint.py:202)
[2018-02-17 02:47:48]     INFO --- Starting new HTTPS connection (1): s3.amazonaws.com (connectionpool.py:735)
[2018-02-17 02:47:49]    DEBUG --- "PUT /ads-part2-assign2 HTTP/1.1" 200 0 (connectionpool.py:383)
[2018-02-17 02:47:49]    DEBUG --- Response headers: {'x-amz-id-2': 'CM2yODYuMkdfmqYF+GtQ9jDiyi+AvrTSD8eU8XO4uhOGp0CEeCqzRcusNVgN0R/8ZtnBkacpKck=', 'x-amz-request-id': '33497DF91CAAB4AE', 'date': 'Sat, 17 Feb 2018 02:47:49 GMT', 'location': '/ads-part2-assign2', 'content-length': '0', 'server': 'AmazonS3'} (parsers.py:204)
[2018-02-17 02:47:49]    DEBUG --- Response body:
b'' (parsers.py:205)
[2018-02-17 02:47:49]    DEBUG --- Event needs-retry.s3.CreateBucket: calling handler <botocore.retryhandler.RetryHandler object at 0x7f91a811c1d0> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- No retry needed. (retryhandler.py:187)
[2018-02-17 02:47:49]    DEBUG --- Event needs-retry.s3.CreateBucket: calling handler <bound method S3RegionRedirector.redirect_from_error of <botocore.utils.S3RegionRedirector object at 0x7f91a811c9b0>> (hooks.py:209)
[2018-02-17 02:47:49]     INFO --- Connection is successful (ADSAssign1Part2Final.py:433)
[2018-02-17 02:47:49]    DEBUG --- Acquiring 0 (utils.py:548)
[2018-02-17 02:47:49]    DEBUG --- UploadSubmissionTask(transfer_id=0, {'transfer_future': <s3transfer.futures.TransferFuture object at 0x7f91ae634ba8>}) about to wait for the following futures [] (tasks.py:194)
[2018-02-17 02:47:49]    DEBUG --- UploadSubmissionTask(transfer_id=0, {'transfer_future': <s3transfer.futures.TransferFuture object at 0x7f91ae634ba8>}) done waiting for dependent futures (tasks.py:203)
[2018-02-17 02:47:49]    DEBUG --- Executing task UploadSubmissionTask(transfer_id=0, {'transfer_future': <s3transfer.futures.TransferFuture object at 0x7f91ae634ba8>}) with kwargs {'client': <botocore.client.S3 object at 0x7f91a5ec60b8>, 'config': <boto3.s3.transfer.TransferConfig object at 0x7f91ae6342e8>, 'osutil': <s3transfer.utils.OSUtils object at 0x7f91ae634080>, 'request_executor': <s3transfer.futures.BoundedExecutor object at 0x7f91ae634048>, 'transfer_future': <s3transfer.futures.TransferFuture object at 0x7f91ae634ba8>} (tasks.py:147)
[2018-02-17 02:47:49]    DEBUG --- Submitting task PutObjectTask(transfer_id=0, {'bucket': 'ads-part2-assign2', 'key': 'ADSAssign1Part2.zip', 'extra_args': {}}) to executor <s3transfer.futures.BoundedExecutor object at 0x7f91ae634048> for transfer request: 0. (futures.py:286)
[2018-02-17 02:47:49]    DEBUG --- Acquiring 0 (utils.py:548)
[2018-02-17 02:47:49]    DEBUG --- PutObjectTask(transfer_id=0, {'bucket': 'ads-part2-assign2', 'key': 'ADSAssign1Part2.zip', 'extra_args': {}}) about to wait for the following futures [] (tasks.py:194)
[2018-02-17 02:47:49]    DEBUG --- Releasing acquire 0/None (utils.py:561)
[2018-02-17 02:47:49]    DEBUG --- PutObjectTask(transfer_id=0, {'bucket': 'ads-part2-assign2', 'key': 'ADSAssign1Part2.zip', 'extra_args': {}}) done waiting for dependent futures (tasks.py:203)
[2018-02-17 02:47:49]    DEBUG --- Executing task PutObjectTask(transfer_id=0, {'bucket': 'ads-part2-assign2', 'key': 'ADSAssign1Part2.zip', 'extra_args': {}}) with kwargs {'client': <botocore.client.S3 object at 0x7f91a5ec60b8>, 'fileobj': <s3transfer.utils.ReadFileChunk object at 0x7f91ae634c88>, 'bucket': 'ads-part2-assign2', 'key': 'ADSAssign1Part2.zip', 'extra_args': {}} (tasks.py:147)
[2018-02-17 02:47:49]    DEBUG --- Event before-parameter-build.s3.PutObject: calling handler <function validate_ascii_metadata at 0x7f91b538c950> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event before-parameter-build.s3.PutObject: calling handler <function sse_md5 at 0x7f91b5389d08> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event before-parameter-build.s3.PutObject: calling handler <function convert_body_to_file_like_object at 0x7f91b538d0d0> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event before-parameter-build.s3.PutObject: calling handler <function validate_bucket_name at 0x7f91b5389c80> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event before-parameter-build.s3.PutObject: calling handler <bound method S3RegionRedirector.redirect_from_cache of <botocore.utils.S3RegionRedirector object at 0x7f91a811c9b0>> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event before-parameter-build.s3.PutObject: calling handler <function generate_idempotent_uuid at 0x7f91b53898c8> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event before-call.s3.PutObject: calling handler <function conditionally_calculate_md5 at 0x7f91b5389bf8> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event before-call.s3.PutObject: calling handler <function add_expect_header at 0x7f91b538c1e0> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Adding expect 100 continue header to request. (handlers.py:332)
[2018-02-17 02:47:49]    DEBUG --- Event before-call.s3.PutObject: calling handler <bound method S3RegionRedirector.set_request_url of <botocore.utils.S3RegionRedirector object at 0x7f91a811c9b0>> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Making request for OperationModel(name=PutObject) (verify_ssl=True) with params: {'url_path': '/ads-part2-assign2/ADSAssign1Part2.zip', 'query_string': {}, 'method': 'PUT', 'headers': {'User-Agent': 'Boto3/1.5.30 Python/3.6.4 Linux/4.4.111-boot2docker Botocore/1.8.44', 'Content-MD5': 'B8nyxTtDGZrJ/R0jnpvIkA==', 'Expect': '100-continue'}, 'body': <s3transfer.utils.ReadFileChunk object at 0x7f91ae634c88>, 'url': 'https://s3.amazonaws.com/ads-part2-assign2/ADSAssign1Part2.zip', 'context': {'client_region': 'us-east-1', 'client_config': <botocore.config.Config object at 0x7f91a5eccb00>, 'has_streaming_input': True, 'auth_type': None, 'signing': {'bucket': 'ads-part2-assign2'}}} (endpoint.py:142)
[2018-02-17 02:47:49]    DEBUG --- Event request-created.s3.PutObject: calling handler <function signal_not_transferring at 0x7f91a7fc0268> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event request-created.s3.PutObject: calling handler <bound method RequestSigner.handler of <botocore.signers.RequestSigner object at 0x7f91a5ec60f0>> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event choose-signer.s3.PutObject: calling handler <bound method ClientCreator._default_s3_presign_to_sigv2 of <botocore.client.ClientCreator object at 0x7f91a5eb5fd0>> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event choose-signer.s3.PutObject: calling handler <function set_operation_specific_signer at 0x7f91b53897b8> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Event before-sign.s3.PutObject: calling handler <function fix_s3_host at 0x7f91b56d2268> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Calculating signature using v4 auth. (auth.py:359)
[2018-02-17 02:47:49]    DEBUG --- CanonicalRequest:
PUT
/ads-part2-assign2/ADSAssign1Part2.zip

content-md5:B8nyxTtDGZrJ/R0jnpvIkA==
host:s3.amazonaws.com
x-amz-content-sha256:UNSIGNED-PAYLOAD
x-amz-date:20180217T024749Z

content-md5;host;x-amz-content-sha256;x-amz-date
UNSIGNED-PAYLOAD (auth.py:360)
[2018-02-17 02:47:49]    DEBUG --- StringToSign:
AWS4-HMAC-SHA256
20180217T024749Z
20180217/us-east-1/s3/aws4_request
2390e262d6ee31ea2bff9b5d0ffbf7910a2182476132b58d906fec29c3ddc028 (auth.py:362)
[2018-02-17 02:47:49]    DEBUG --- Signature:
b2a730ee0a7efb4499e659def61aef73a9a7f1f8cc348f06d359ebc92e404d96 (auth.py:364)
[2018-02-17 02:47:49]    DEBUG --- Event request-created.s3.PutObject: calling handler <function signal_transferring at 0x7f91a7fc02f0> (hooks.py:209)
[2018-02-17 02:47:49]    DEBUG --- Sending http request: <PreparedRequest [PUT]> (endpoint.py:202)
[2018-02-17 02:47:49]    DEBUG --- Waiting for 100 Continue response. (awsrequest.py:161)
[2018-02-17 02:47:49]    DEBUG --- 100 Continue response seen, now sending request body. (awsrequest.py:206)
[2018-02-17 02:47:50]    DEBUG --- "PUT /ads-part2-assign2/ADSAssign1Part2.zip HTTP/1.1" 200 0 (connectionpool.py:383)
[2018-02-17 02:47:50]    DEBUG --- Response headers: {'x-amz-id-2': '/kICSpUStflDyo4FC06AEymYS3xHbOk6OSFmoDJVkK71he/QVUo8/xOCDYocDo6CxvFwG6wz+8I=', 'x-amz-request-id': '1C45C44C30138E82', 'date': 'Sat, 17 Feb 2018 02:47:50 GMT', 'etag': '"07c9f2c53b43199ac9fd1d239e9bc890"', 'content-length': '0', 'server': 'AmazonS3'} (parsers.py:204)
[2018-02-17 02:47:50]    DEBUG --- Response body:
b'' (parsers.py:205)
[2018-02-17 02:47:50]    DEBUG --- Event needs-retry.s3.PutObject: calling handler <botocore.retryhandler.RetryHandler object at 0x7f91a811c1d0> (hooks.py:209)
[2018-02-17 02:47:50]    DEBUG --- No retry needed. (retryhandler.py:187)
[2018-02-17 02:47:50]    DEBUG --- Event needs-retry.s3.PutObject: calling handler <bound method S3RegionRedirector.redirect_from_error of <botocore.utils.S3RegionRedirector object at 0x7f91a811c9b0>> (hooks.py:209)
[2018-02-17 02:47:50]    DEBUG --- Releasing acquire 0/None (utils.py:561)
[2018-02-17 02:47:50]    DEBUG --- Acquiring 0 (utils.py:548)
[2018-02-17 02:47:50]    DEBUG --- UploadSubmissionTask(transfer_id=0, {'transfer_future': <s3transfer.futures.TransferFuture object at 0x7f91ae6344e0>}) about to wait for the following futures [] (tasks.py:194)
[2018-02-17 02:47:50]    DEBUG --- UploadSubmissionTask(transfer_id=0, {'transfer_future': <s3transfer.futures.TransferFuture object at 0x7f91ae6344e0>}) done waiting for dependent futures (tasks.py:203)
[2018-02-17 02:47:50]    DEBUG --- Executing task UploadSubmissionTask(transfer_id=0, {'transfer_future': <s3transfer.futures.TransferFuture object at 0x7f91ae6344e0>}) with kwargs {'client': <botocore.client.S3 object at 0x7f91a5ec60b8>, 'config': <boto3.s3.transfer.TransferConfig object at 0x7f91a811ccf8>, 'osutil': <s3transfer.utils.OSUtils object at 0x7f91ae634320>, 'request_executor': <s3transfer.futures.BoundedExecutor object at 0x7f91ae634978>, 'transfer_future': <s3transfer.futures.TransferFuture object at 0x7f91ae6344e0>} (tasks.py:147)
